{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "This example requires the <a href=\"https://github.com/SeanNaren/deepspeech.pytorch\">deepspeech_pytorch</a> package to be installed. The DeepSpeech class defined below is a modified version of the DeepSpeech class in the <a href=\"https://github.com/SeanNaren/deepspeech.pytorch/blob/master/deepspeech_pytorch/model.py\">models.py</a> module of that package.\n",
    "\n",
    "WARNING: This example script is not yet functional.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import PyTCI\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from omegaconf import OmegaConf\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.nn import CTCLoss\n",
    "torchaudio.set_audio_backend(\"sox_io\")\n",
    "\n",
    "from deepspeech_pytorch.configs.train_config import SpectConfig, BiDirectionalConfig, OptimConfig, AdamConfig, SGDConfig, UniDirectionalConfig\n",
    "from deepspeech_pytorch.configs.inference_config import TranscribeConfig, ModelConfig\n",
    "from deepspeech_pytorch.decoder import Decoder, GreedyDecoder\n",
    "from deepspeech_pytorch.utils import load_decoder, load_model\n",
    "from deepspeech_pytorch.validation import CharErrorRate, WordErrorRate\n",
    "from deepspeech_pytorch.model import SequenceWise, MaskConv, InferenceBatchSoftmax, Lookahead\n",
    "from deepspeech_pytorch.enums import RNNType, SpectrogramWindow\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "LABELS = list(\"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \")\n",
    "MODEL_CFG = BiDirectionalConfig(rnn_type=RNNType.lstm, hidden_size=1024, hidden_layers=7)\n",
    "OPTIM_CFG = AdamConfig(learning_rate=0.00015, learning_anneal=0.99, weight_decay=1e-05, eps=1e-08, betas=[0.9, 0.999])\n",
    "SPECT_CFG = SpectConfig(sample_rate=16000, window_size=0.02, window_stride=0.01, window=SpectrogramWindow.hamming)\n",
    "PRECISION = 16\n",
    "\n",
    "\n",
    "class SpectrogramParser(nn.Module):\n",
    "    def __init__(self, audio_conf: SpectConfig, normalize: bool = False):\n",
    "        \"\"\"\n",
    "       \tParses audio file into spectrogram with optional normalization\n",
    "       \t:param audio_conf: Dictionary containing the sample rate, window and the window length/stride in seconds\n",
    "       \t:param normalize(default False):  Apply standard mean and deviation normalization to audio tensor\n",
    "       \t\"\"\"\n",
    "        super().__init__()\n",
    "        self.window_stride = audio_conf.window_stride\n",
    "        self.window_size = audio_conf.window_size\n",
    "        self.sample_rate = audio_conf.sample_rate\n",
    "        self.window = audio_conf.window.value\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        n_fft = int(self.sample_rate * self.window_size)\n",
    "        win_length = n_fft\n",
    "        hop_length = int(self.sample_rate * self.window_stride)\n",
    "        if self.window == 'hamming':\n",
    "            window = torch.hamming_window\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        self.transform = torchaudio.transforms.Spectrogram(\n",
    "            n_fft, win_length, hop_length, window_fn=window, power=1, normalized=False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, audio):\n",
    "        if audio.shape[0] == 1:\n",
    "            audio = audio.squeeze() # mono\n",
    "        else:\n",
    "            audio = audio.mean(axis=0) # multiple channels, average\n",
    "        \n",
    "        spect = self.transform(audio)\n",
    "        spect = torch.log1p(spect)\n",
    "        \n",
    "        if self.normalize:\n",
    "            mean = spect.mean()\n",
    "            std = spect.std()\n",
    "            spect.add_(-mean)\n",
    "            spect.div_(std)\n",
    "        \n",
    "        return spect.T.contiguous()\n",
    "\n",
    "\n",
    "class BatchRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, rnn_type=nn.LSTM, bidirectional=False, batch_norm=True):\n",
    "        super(BatchRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.batch_norm = SequenceWise(nn.BatchNorm1d(input_size)) if batch_norm else None\n",
    "        self.rnn = rnn_type(input_size=input_size, hidden_size=hidden_size,\n",
    "                            bidirectional=bidirectional, bias=True)\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        self.rnn.flatten_parameters()\n",
    "\n",
    "    def forward(self, x, output_lengths):\n",
    "        if self.batch_norm is not None:\n",
    "            x = self.batch_norm(x)\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, output_lengths, enforce_sorted=False)\n",
    "        x, h = self.rnn(x)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x)\n",
    "        if self.bidirectional:\n",
    "            x = x.view(x.size(0), x.size(1), 2, -1).sum(2).view(x.size(0), x.size(1), -1)  # (TxNxH*2) -> (TxNxH) by sum\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepSpeech(pl.LightningModule):\n",
    "    def __init__(self, labels=LABELS, model_cfg=MODEL_CFG, precision=PRECISION, optim_cfg=OPTIM_CFG, spect_cfg=SPECT_CFG):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model_cfg = model_cfg\n",
    "        self.precision = precision\n",
    "        self.optim_cfg = optim_cfg\n",
    "        self.spect_cfg = spect_cfg\n",
    "        self.bidirectional = True if OmegaConf.get_type(model_cfg) is BiDirectionalConfig else False\n",
    "\n",
    "        self.labels = labels\n",
    "        num_classes = len(self.labels)\n",
    "\n",
    "        self.conv = MaskConv(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ))\n",
    "        # Based on above convolutions and spectrogram size using conv formula (W - F + 2P)/ S+1\n",
    "        rnn_input_size = int(math.floor((self.spect_cfg.sample_rate * self.spect_cfg.window_size) / 2) + 1)\n",
    "        rnn_input_size = int(math.floor(rnn_input_size + 2 * 20 - 41) / 2 + 1)\n",
    "        rnn_input_size = int(math.floor(rnn_input_size + 2 * 10 - 21) / 2 + 1)\n",
    "        rnn_input_size *= 32\n",
    "\n",
    "        self.rnns = nn.Sequential(\n",
    "            BatchRNN(\n",
    "                input_size=rnn_input_size,\n",
    "                hidden_size=self.model_cfg.hidden_size,\n",
    "                rnn_type=self.model_cfg.rnn_type.value,\n",
    "                bidirectional=self.bidirectional,\n",
    "                batch_norm=False\n",
    "            ),\n",
    "            *(\n",
    "                BatchRNN(\n",
    "                    input_size=self.model_cfg.hidden_size,\n",
    "                    hidden_size=self.model_cfg.hidden_size,\n",
    "                    rnn_type=self.model_cfg.rnn_type.value,\n",
    "                    bidirectional=self.bidirectional\n",
    "                ) for x in range(self.model_cfg.hidden_layers - 3)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.lookahead = nn.Sequential(\n",
    "            # consider adding batch norm?\n",
    "            Lookahead(self.model_cfg.hidden_size, context=self.model_cfg.lookahead_context),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ) if not self.bidirectional else None\n",
    "\n",
    "        fully_connected = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.model_cfg.hidden_size),\n",
    "            nn.Linear(self.model_cfg.hidden_size, num_classes, bias=False)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            SequenceWise(fully_connected),\n",
    "        )\n",
    "        self.inference_softmax = InferenceBatchSoftmax()\n",
    "        self.criterion = CTCLoss(blank=self.labels.index('_'), reduction='sum', zero_infinity=True)\n",
    "        self.evaluation_decoder = GreedyDecoder(self.labels)  # Decoder used for validation\n",
    "        self.wer = WordErrorRate(\n",
    "            decoder=self.evaluation_decoder,\n",
    "            target_decoder=self.evaluation_decoder\n",
    "        )\n",
    "        self.cer = CharErrorRate(\n",
    "            decoder=self.evaluation_decoder,\n",
    "            target_decoder=self.evaluation_decoder\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        lengths = lengths.cpu().int()\n",
    "        output_lengths = self.get_seq_lens(lengths)\n",
    "        x, _ = self.conv(x.transpose(1,2).unsqueeze(1).contiguous(), output_lengths)\n",
    "\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # Collapse feature dimension\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous()  # TxNxH\n",
    "\n",
    "        for rnn in self.rnns:\n",
    "            x = rnn(x, output_lengths)\n",
    "\n",
    "        if not self.bidirectional:  # no need for lookahead layer in bidirectional\n",
    "            x = self.lookahead(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        # identity in training mode, softmax in eval mode\n",
    "        x = self.inference_softmax(x)\n",
    "        return x, output_lengths\n",
    "    \n",
    "    def unpack_batch(self, batch):\n",
    "        inputs = batch.get('inputs', None)\n",
    "        input_lengths = batch.get('input_lengths', None)\n",
    "        labels = batch.get('labels', None)\n",
    "        label_lengths = batch.get('label_lengths', None)\n",
    "        \n",
    "        return inputs, labels, input_lengths, label_lengths\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets, input_sizes, target_sizes = self.unpack_batch(batch)\n",
    "        if inputs is None: # skip step\n",
    "            return None\n",
    "        \n",
    "        out, output_sizes = self(inputs, input_sizes)\n",
    "        out = out.transpose(0, 1)  # TxNxH\n",
    "        out = out.log_softmax(-1)\n",
    "\n",
    "        loss = self.criterion(out, targets, output_sizes, target_sizes)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets, input_sizes, target_sizes = self.unpack_batch(batch)\n",
    "        if inputs is None: # skip step\n",
    "            return\n",
    "        \n",
    "        inputs = inputs.to(self.device)\n",
    "        with autocast(enabled=self.precision == 16):\n",
    "            out, output_sizes = self(inputs, input_sizes)\n",
    "        decoded_output, _ = self.evaluation_decoder.decode(out, output_sizes)\n",
    "        \n",
    "        self.wer(preds=out, preds_sizes=output_sizes, targets=targets, target_sizes=target_sizes)\n",
    "        self.cer(preds=out, preds_sizes=output_sizes, targets=targets, target_sizes=target_sizes)\n",
    "        self.log('wer', self.wer.compute(), prog_bar=True, on_epoch=True)\n",
    "        self.log('cer', self.cer.compute(), prog_bar=True, on_epoch=True)\n",
    "    \n",
    "    def test_step(self, *args):\n",
    "        return self.validation_step(*args)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if OmegaConf.get_type(self.optim_cfg) is SGDConfig:\n",
    "            optimizer = torch.optim.SGD(\n",
    "                params=self.parameters(),\n",
    "                lr=self.optim_cfg.learning_rate,\n",
    "                momentum=self.optim_cfg.momentum,\n",
    "                nesterov=True,\n",
    "                weight_decay=self.optim_cfg.weight_decay\n",
    "            )\n",
    "        elif OmegaConf.get_type(self.optim_cfg) is AdamConfig:\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                params=self.parameters(),\n",
    "                lr=self.optim_cfg.learning_rate,\n",
    "                betas=self.optim_cfg.betas,\n",
    "                eps=self.optim_cfg.eps,\n",
    "                weight_decay=self.optim_cfg.weight_decay\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Optimizer has not been specified correctly.\")\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer=optimizer,\n",
    "            gamma=self.optim_cfg.learning_anneal\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def get_seq_lens(self, input_length):\n",
    "        \"\"\"\n",
    "        Given a 1D Tensor or Variable containing integer sequence lengths, return a 1D tensor or variable\n",
    "        containing the size sequences that will be output by the network.\n",
    "        :param input_length: 1D Tensor\n",
    "        :return: 1D Tensor scaled by model\n",
    "        \"\"\"\n",
    "        seq_len = input_length\n",
    "        for m in self.conv.modules():\n",
    "            if type(m) == nn.modules.conv.Conv2d:\n",
    "                seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) // m.stride[1] + 1)\n",
    "        return seq_len.int()\n",
    "    \n",
    "    def activation_fx(self, layer, log=True):\n",
    "        def activation(x):\n",
    "            lengths = [x.shape[1]] * x.shape[0]\n",
    "            output_lengths = self.get_seq_lens(lengths)\n",
    "            \n",
    "            #x, _ = model.conv(x, output_lengths)\n",
    "            for module in self.conv.seq_module:\n",
    "                x = module(x)\n",
    "                mask = torch.BoolTensor(x.size()).fill_(0)\n",
    "                if x.is_cuda:\n",
    "                    mask = mask.cuda()\n",
    "                for i, length in enumerate(output_lengths):\n",
    "                    length = length.item()\n",
    "                    if (mask[i].size(2) - length) > 0:\n",
    "                        mask[i].narrow(2, length, mask[i].size(2) - length).fill_(1)\n",
    "                x = x.masked_fill(mask, 0)\n",
    "                \n",
    "                if isinstance(module, torch.nn.Hardtanh):\n",
    "                    layer -= 1\n",
    "                    if layer < 0:\n",
    "                        break\n",
    "            \n",
    "            sizes = x.size()\n",
    "            x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # Collapse feature dimension\n",
    "            x = x.transpose(1, 2).transpose(0, 1).contiguous()  # TxNxH\n",
    "            if layer < 0:\n",
    "                return x.detach().cpu().numpy()\n",
    "            \n",
    "            for rnn in self.rnns:\n",
    "                x = rnn(x, output_lengths)\n",
    "                layer -= 1\n",
    "                if layer < 0:\n",
    "                    return x.detach().cpu().numpy()\n",
    "            \n",
    "            if not self.bidirectional:  # no need for lookahead layer in bidirectional\n",
    "                x = self.lookahead(x)\n",
    "            \n",
    "            x = self.fc(x)\n",
    "            \n",
    "            # identity in training mode, softmax in eval mode\n",
    "            if log:\n",
    "                x = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "            else:\n",
    "                x = torch.nn.functional.softmax(x, dim=-1)\n",
    "            layer -= 1\n",
    "            if layer < 0:\n",
    "                return x.detach().cpu().numpy()\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        return activation\n",
    "\n",
    "\n",
    "spect_parser = SpectrogramParser(audio_conf=SPECT_CFG, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TCI analyzer\n",
    "analyzer = PyTCI.Analyzer(out_sr=1000, model=model, threshold=0.75, verbose=True)\n",
    "\n",
    "# Feed list of source segments to analyzer\n",
    "analyzer.set_segments(segments, sr=1000)\n",
    "\n",
    "# Estimate integration periods using TCI paradigm\n",
    "intwin_tci = analyzer.estimate_integration_window()\n",
    "\n",
    "# Compare results\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(np.log([0.016, 1.2]), np.log([0.016, 1.2]), 'k--', linewidth=1)\n",
    "plt.plot(\n",
    "    np.log(intwin_cdf),\n",
    "    np.log(intwin_tci),\n",
    "    '-o'\n",
    ")\n",
    "plt.xticks(np.log([0.02, 0.16, 1.2]), [20, 160, 1200], fontsize=12)\n",
    "plt.yticks(np.log([0.02, 0.16, 1.2]), [20, 160, 1200], fontsize=12)\n",
    "plt.xlabel('Integration window\\nfrom CDF (ms)', fontsize=12)\n",
    "plt.ylabel('Integration window\\nfrom TCI (ms)', fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch_cuda11]",
   "language": "python",
   "name": "conda-env-.conda-torch_cuda11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
